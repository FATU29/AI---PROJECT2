{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Heart Disease Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "# Create directories for outputs if they don't exist\n",
    "os.makedirs('../output/trees', exist_ok=True)\n",
    "os.makedirs('../output/plots', exist_ok=True)\n",
    "os.makedirs('../output/tables', exist_ok=True)\n",
    "\n",
    "# Define column names based on heart-disease.names\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', \n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/processed.cleveland.data'\n",
    "df = pd.read_csv(file_path, header=None, names=column_names, na_values='?')\n",
    "\n",
    "# Display first 5 rows and info\n",
    "print(\"Original Data Head:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "# Display basic statistics and save to file\n",
    "print(\"\\nBasic Statistics:\")\n",
    "stats_table = df.describe()\n",
    "display(stats_table)\n",
    "stats_table.to_csv('../output/tables/basic_statistics.csv')\n",
    "print(\"Basic statistics saved to ../output/tables/basic_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing\n",
    "\n",
    "1.  **Handle Missing Values**: The dataset contains a few missing values marked as `?`. We will drop rows with any missing values as they are a small fraction of the total data.\n",
    "2.  **Target Variable Transformation**: The `target` column indicates the presence of heart disease, with 0 for no disease and 1, 2, 3, 4 for varying degrees of disease. As per the project specification, we will convert this into a binary classification problem: 0 for 'No Disease' and 1 for 'Disease'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values before cleaning:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Save missing values report\n",
    "missing_values.to_csv('../output/tables/missing_values_report.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"\\nRows dropped: {len(df) - len(df_clean)}\")\n",
    "print(f\"Percentage of data retained: {len(df_clean)/len(df)*100:.2f}%\")\n",
    "\n",
    "# Transform target variable: 0 = No Disease, >0 = Disease\n",
    "print(\"\\nOriginal target distribution:\")\n",
    "original_target_dist = df_clean['target'].value_counts().sort_index()\n",
    "print(original_target_dist)\n",
    "\n",
    "# Visualize original target distribution and save\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "original_target_dist.plot(kind='bar', alpha=0.7)\n",
    "plt.title('Original Target Distribution')\n",
    "plt.xlabel('Target Value')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "df_clean['target'] = (df_clean['target'] > 0).astype(int)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df_clean.drop('target', axis=1)\n",
    "y = df_clean['target']\n",
    "\n",
    "print(f\"\\nShape of data after cleaning: {df_clean.shape}\")\n",
    "print(\"\\nTarget variable distribution after transformation:\")\n",
    "new_target_dist = y.value_counts()\n",
    "print(new_target_dist)\n",
    "\n",
    "# Visualize new target distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "new_target_dist.plot(kind='bar', alpha=0.7, color=['skyblue', 'lightcoral'])\n",
    "plt.title('Binary Target Distribution')\n",
    "plt.xlabel('Target Value (0=No Disease, 1=Disease)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/target_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save target distribution data\n",
    "target_summary = pd.DataFrame({\n",
    "    'Original Distribution': original_target_dist,\n",
    "    'Binary Distribution': [new_target_dist[0], new_target_dist[1], 0, 0, 0]\n",
    "})\n",
    "target_summary.to_csv('../output/tables/target_distribution_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preparing the Datasets\n",
    "\n",
    "We will create four training and testing subsets with different proportions (40/60, 60/40, 80/20, 90/10) using stratified splitting to maintain the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    '40/60': train_test_split(X, y, test_size=0.60, random_state=42, stratify=y),\n",
    "    '60/40': train_test_split(X, y, test_size=0.40, random_state=42, stratify=y),\n",
    "    '80/20': train_test_split(X, y, test_size=0.20, random_state=42, stratify=y),\n",
    "    '90/10': train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)\n",
    "}\n",
    "\n",
    "print(\"Created the following splits (train/test):\")\n",
    "split_summary = []\n",
    "for name, data in splits.items():\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    print(f\"- {name}: Train shape={X_train.shape}, Test shape={X_test.shape}\")\n",
    "    print(f\"  Train class distribution: {y_train.value_counts().to_dict()}\")\n",
    "    print(f\"  Test class distribution: {y_test.value_counts().to_dict()}\")\n",
    "    print()\n",
    "    \n",
    "    # Store for summary table\n",
    "    split_summary.append({\n",
    "        'Split': name,\n",
    "        'Train Size': len(X_train),\n",
    "        'Test Size': len(X_test),\n",
    "        'Train No Disease': y_train.value_counts()[0],\n",
    "        'Train Disease': y_train.value_counts()[1],\n",
    "        'Test No Disease': y_test.value_counts()[0],\n",
    "        'Test Disease': y_test.value_counts()[1]\n",
    "    })\n",
    "\n",
    "# Create and save split summary table\n",
    "split_summary_df = pd.DataFrame(split_summary)\n",
    "print(\"Split Summary Table:\")\n",
    "display(split_summary_df)\n",
    "split_summary_df.to_csv('../output/tables/split_summary.csv', index=False)\n",
    "\n",
    "# Visualize split sizes and save\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Train/Test sizes\n",
    "splits_names = list(splits.keys())\n",
    "train_sizes = [len(splits[name][0]) for name in splits_names]\n",
    "test_sizes = [len(splits[name][1]) for name in splits_names]\n",
    "\n",
    "x = np.arange(len(splits_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, train_sizes, width, label='Train Size', alpha=0.7)\n",
    "axes[0].bar(x + width/2, test_sizes, width, label='Test Size', alpha=0.7)\n",
    "axes[0].set_title('Train/Test Split Sizes')\n",
    "axes[0].set_xlabel('Split Ratio')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(splits_names)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Class proportions\n",
    "train_proportions = []\n",
    "test_proportions = []\n",
    "for name in splits_names:\n",
    "    _, _, y_train, y_test = splits[name]\n",
    "    train_props = y_train.value_counts(normalize=True).sort_index()\n",
    "    test_props = y_test.value_counts(normalize=True).sort_index()\n",
    "    train_proportions.append(train_props[1])  # Disease proportion\n",
    "    test_proportions.append(test_props[1])    # Disease proportion\n",
    "\n",
    "axes[1].plot(splits_names, train_proportions, 'o-', label='Train Disease %', linewidth=2, markersize=8)\n",
    "axes[1].plot(splits_names, test_proportions, 's-', label='Test Disease %', linewidth=2, markersize=8)\n",
    "axes[1].set_title('Disease Class Proportion Across Splits')\n",
    "axes[1].set_xlabel('Split Ratio')\n",
    "axes[1].set_ylabel('Disease Proportion')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0.4, 0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/split_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Class Distributions\n",
    "\n",
    "Let's visualize the class distributions across the original dataset and all splits to confirm that stratification worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to hold all distribution plots\n",
    "fig, axes = plt.subplots(5, 2, figsize=(14, 22))\n",
    "fig.suptitle('Class Distributions Across All Datasets', fontsize=16, y=1.02)\n",
    "\n",
    "# 1. Original Dataset\n",
    "y_labels = y.map({0: 'No Disease', 1: 'Disease'})\n",
    "sns.countplot(x=y_labels, ax=axes[0, 0], order=['No Disease', 'Disease'])\n",
    "axes[0, 0].set_title('1. Original Dataset Distribution')\n",
    "axes[0, 0].set_xlabel(None)\n",
    "# Add count annotations\n",
    "for i, v in enumerate(y.value_counts().sort_index()):\n",
    "    axes[0, 0].text(i, v + 1, str(v), ha='center', va='bottom')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# 2. Distributions for each split\n",
    "for i, (name, data) in enumerate(splits.items()):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    row = i + 1\n",
    "\n",
    "    y_train_labels = y_train.map({0: 'No Disease', 1: 'Disease'})\n",
    "    y_test_labels = y_test.map({0: 'No Disease', 1: 'Disease'})\n",
    "\n",
    "    # Plot Training Set Distribution\n",
    "    sns.countplot(x=y_train_labels, ax=axes[row, 0], order=['No Disease', 'Disease'])\n",
    "    axes[row, 0].set_title(f'{i+2}. Train Set ({name} split)')\n",
    "    axes[row, 0].set_xlabel(None)\n",
    "    # Add count annotations\n",
    "    for j, v in enumerate(y_train.value_counts().sort_index()):\n",
    "        axes[row, 0].text(j, v + 1, str(v), ha='center', va='bottom')\n",
    "\n",
    "    # Plot Test Set Distribution\n",
    "    sns.countplot(x=y_test_labels, ax=axes[row, 1], order=['No Disease', 'Disease'])\n",
    "    axes[row, 1].set_title(f'{i+2}. Test Set ({name} split)')\n",
    "    axes[row, 1].set_xlabel(None)\n",
    "    # Add count annotations\n",
    "    for j, v in enumerate(y_test.value_counts().sort_index()):\n",
    "        axes[row, 1].text(j, v + 1, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "plt.savefig('../output/plots/class_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 & 2.3 Building and Evaluating Decision Tree Classifiers\n",
    "\n",
    "For each split, we will:\n",
    "1.  Fit a `DecisionTreeClassifier` using information gain (`criterion='entropy'`).\n",
    "2.  Visualize the resulting tree.\n",
    "3.  Predict on the test set and generate a `classification_report` and a `confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "class_names = ['No Disease', 'Disease']\n",
    "\n",
    "# Store results for summary\n",
    "results_summary = []\n",
    "classification_reports = []\n",
    "\n",
    "for name, data in splits.items():\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Split: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. Fit the classifier\n",
    "    dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # 2. Visualize and save the tree\n",
    "    dot_data = export_graphviz(dt_classifier, out_file=None, \n",
    "                               feature_names=feature_names,\n",
    "                               class_names=class_names,\n",
    "                               filled=True, rounded=True,  \n",
    "                               special_characters=True)\n",
    "    \n",
    "    graph_title = f'Decision_Tree_for_{name.replace(\"/\", \"-\")}_Split'\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(f\"../output/trees/{graph_title}\", format='png', cleanup=True)\n",
    "    print(f\"\\nDecision Tree for {name} split saved to ../output/trees/{graph_title}.png\")\n",
    "    display(graph)\n",
    "\n",
    "    # 3. Evaluate the classifier\n",
    "    y_pred = dt_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nClassification Report for {name} split:\")\n",
    "    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "    report_str = classification_report(y_test, y_pred, target_names=class_names)\n",
    "    print(report_str)\n",
    "    \n",
    "    # Save classification report to file\n",
    "    with open(f'../output/tables/classification_report_{name.replace(\"/\", \"-\")}.txt', 'w') as f:\n",
    "        f.write(f\"Classification Report for {name} split:\\n\")\n",
    "        f.write(report_str)\n",
    "\n",
    "    # Store results\n",
    "    results_summary.append({\n",
    "        'Split': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision (No Disease)': report['No Disease']['precision'],\n",
    "        'Recall (No Disease)': report['No Disease']['recall'],\n",
    "        'F1-Score (No Disease)': report['No Disease']['f1-score'],\n",
    "        'Precision (Disease)': report['Disease']['precision'],\n",
    "        'Recall (Disease)': report['Disease']['recall'],\n",
    "        'F1-Score (Disease)': report['Disease']['f1-score']\n",
    "    })\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Confusion Matrix for {name} split')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # Add metrics as text\n",
    "    plt.figtext(0.02, 0.02, f'Accuracy: {accuracy:.3f}', fontsize=10, \n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.savefig(f'../output/plots/confusion_matrix_{name.replace(\"/\", \"-\")}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save confusion matrix data\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    cm_df.to_csv(f'../output/tables/confusion_matrix_{name.replace(\"/\", \"-\")}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "print(\"Performance Summary Across All Splits:\")\n",
    "display(summary_df.round(3))\n",
    "\n",
    "# Save summary table\n",
    "summary_df.to_csv('../output/tables/performance_summary.csv', index=False)\n",
    "print(\"Performance summary saved to ../output/tables/performance_summary.csv\")\n",
    "\n",
    "# Plot performance comparison and save\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Performance Metrics Comparison Across Splits', fontsize=16)\n",
    "\n",
    "# Plot 1: Accuracy\n",
    "axes[0, 0].bar(summary_df['Split'], summary_df['Accuracy'], alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Accuracy Across Splits')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "for i, v in enumerate(summary_df['Accuracy']):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Precision for Disease class\n",
    "axes[0, 1].bar(summary_df['Split'], summary_df['Precision (Disease)'], alpha=0.7, color='lightcoral')\n",
    "axes[0, 1].set_title('Precision (Disease) Across Splits')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "for i, v in enumerate(summary_df['Precision (Disease)']):\n",
    "    axes[0, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Recall for Disease class\n",
    "axes[1, 0].bar(summary_df['Split'], summary_df['Recall (Disease)'], alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_title('Recall (Disease) Across Splits')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "for i, v in enumerate(summary_df['Recall (Disease)']):\n",
    "    axes[1, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: F1-Score for Disease class\n",
    "axes[1, 1].bar(summary_df['Split'], summary_df['F1-Score (Disease)'], alpha=0.7, color='gold')\n",
    "axes[1, 1].set_title('F1-Score (Disease) Across Splits')\n",
    "axes[1, 1].set_ylabel('F1-Score')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "for i, v in enumerate(summary_df['F1-Score (Disease)']):\n",
    "    axes[1, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create a comprehensive comparison plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "x = np.arange(len(summary_df['Split']))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x - 1.5*width, summary_df['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "plt.bar(x - 0.5*width, summary_df['Precision (Disease)'], width, label='Precision (Disease)', alpha=0.8)\n",
    "plt.bar(x + 0.5*width, summary_df['Recall (Disease)'], width, label='Recall (Disease)', alpha=0.8)\n",
    "plt.bar(x + 1.5*width, summary_df['F1-Score (Disease)'], width, label='F1-Score (Disease)', alpha=0.8)\n",
    "\n",
    "plt.title('All Performance Metrics Comparison', fontsize=16)\n",
    "plt.xlabel('Split Ratio')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(x, summary_df['Split'])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/comprehensive_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights on Classifier Performance (Task 2.3)\n",
    "\n",
    "**Key Observations from the Analysis:**\n",
    "\n",
    "1. **Impact of Training Set Size**: As the training set size increases from 40% to 90%, we observe a general improvement in model performance. This demonstrates the importance of having sufficient training data for decision trees to learn meaningful patterns.\n",
    "\n",
    "2. **Optimal Split Performance**: The 80/20 and 90/10 splits consistently show the best performance across all metrics, suggesting that these ratios provide the optimal balance between training data quantity and test set reliability.\n",
    "\n",
    "3. **Confusion Matrix Analysis**: \n",
    "   - **True Negatives (TN)**: Correctly identified healthy patients\n",
    "   - **True Positives (TP)**: Correctly identified patients with heart disease\n",
    "   - **False Positives (FP)**: Healthy patients incorrectly classified as having disease\n",
    "   - **False Negatives (FN)**: Patients with disease incorrectly classified as healthy (most critical error)\n",
    "\n",
    "4. **Clinical Implications**: In medical diagnosis, False Negatives are particularly concerning as they represent missed diagnoses. The models show good recall rates, indicating they successfully identify most patients with heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 The Depth and Accuracy of a Decision Tree\n",
    "\n",
    "This task focuses on the 80/20 split. We will analyze how the `max_depth` parameter affects classification accuracy by trying values: `None, 2, 3, 4, 5, 6, 7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_80, X_test_80, y_train_80, y_test_80 = splits['80/20']\n",
    "\n",
    "depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "accuracies = []\n",
    "train_accuracies = []\n",
    "tree_nodes = []  # To track tree complexity\n",
    "tree_depths = []  # To track actual tree depths\n",
    "\n",
    "print(\"--- Analyzing Decision Trees for each max_depth ---\")\n",
    "\n",
    "for depth in depths:\n",
    "    # Create and fit the model\n",
    "    dt_depth = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)\n",
    "    dt_depth.fit(X_train_80, y_train_80)\n",
    "    \n",
    "    # Make predictions and calculate accuracy\n",
    "    y_pred_depth = dt_depth.predict(X_test_80)\n",
    "    accuracy = accuracy_score(y_test_80, y_pred_depth)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Calculate training accuracy for overfitting analysis\n",
    "    train_accuracy = accuracy_score(y_train_80, dt_depth.predict(X_train_80))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Track tree complexity\n",
    "    tree_nodes.append(dt_depth.tree_.node_count)\n",
    "    tree_depths.append(dt_depth.tree_.max_depth)\n",
    "    \n",
    "    # Visualize and save the tree\n",
    "    depth_str = 'None' if depth is None else str(depth)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Tree for max_depth = {depth_str}\")\n",
    "    print(f\"Actual tree depth: {dt_depth.tree_.max_depth}\")\n",
    "    print(f\"Number of nodes: {dt_depth.tree_.node_count}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Overfitting Gap: {train_accuracy - accuracy:.4f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    dot_data = export_graphviz(dt_depth, out_file=None, \n",
    "                               feature_names=feature_names,\n",
    "                               class_names=class_names,\n",
    "                               filled=True, rounded=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    \n",
    "    # Save tree image\n",
    "    graph.render(f'../output/trees/depth_analysis_tree_depth_{depth_str}', \n",
    "                 format='png', cleanup=True)\n",
    "    print(f\"Tree saved to ../output/trees/depth_analysis_tree_depth_{depth_str}.png\")\n",
    "    \n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth vs. Accuracy Analysis Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive analysis table\n",
    "depth_labels = ['None' if d is None else str(d) for d in depths]\n",
    "depth_analysis = pd.DataFrame({\n",
    "    'max_depth': depth_labels,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': accuracies,\n",
    "    'Accuracy Gap': [train - test for train, test in zip(train_accuracies, accuracies)],\n",
    "    'Tree Nodes': tree_nodes,\n",
    "    'Actual Depth': tree_depths\n",
    "})\n",
    "\n",
    "print(\"Comprehensive Depth vs. Accuracy Analysis:\")\n",
    "display(depth_analysis.round(4))\n",
    "\n",
    "# Save the analysis table\n",
    "depth_analysis.to_csv('../output/tables/depth_vs_accuracy_analysis.csv', index=False)\n",
    "print(\"\\nTable saved to ../output/tables/depth_vs_accuracy_analysis.csv\")\n",
    "\n",
    "# Find optimal depth\n",
    "optimal_idx = np.argmax(accuracies)\n",
    "optimal_depth = depth_labels[optimal_idx]\n",
    "print(f\"\\nOptimal max_depth for best test accuracy: {optimal_depth}\")\n",
    "print(f\"Best test accuracy: {accuracies[optimal_idx]:.4f}\")\n",
    "\n",
    "# Create a styled table visualization and save\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table\n",
    "table_data = depth_analysis.round(4)\n",
    "table = ax.table(cellText=table_data.values, colLabels=table_data.columns,\n",
    "                cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.8)\n",
    "\n",
    "# Style the table\n",
    "for i in range(len(table_data.columns)):\n",
    "    table[(0, i)].set_facecolor('#4472C4')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Highlight optimal row\n",
    "for i in range(len(table_data.columns)):\n",
    "    table[(optimal_idx + 1, i)].set_facecolor('#D5E8D4')\n",
    "\n",
    "plt.title('Depth vs. Accuracy Analysis Table', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.savefig('../output/plots/depth_analysis_table.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Charts and Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Decision Tree Depth Analysis (80/20 Split)', fontsize=16)\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_depths = [d if d is not None else 8 for d in depths]\n",
    "plot_labels = [str(d) if d is not None else 'None' for d in depths]\n",
    "\n",
    "# 1. Accuracy Comparison\n",
    "axes[0, 0].plot(plot_depths, train_accuracies, 'o-', label='Training Accuracy', \n",
    "                linewidth=3, markersize=8, color='blue')\n",
    "axes[0, 0].plot(plot_depths, accuracies, 's-', label='Test Accuracy', \n",
    "                linewidth=3, markersize=8, color='red')\n",
    "axes[0, 0].set_title('Training vs Test Accuracy', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('max_depth')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_xticks(plot_depths)\n",
    "axes[0, 0].set_xticklabels(plot_labels)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_ylim(0.7, 1.05)\n",
    "\n",
    "# Add accuracy values as annotations\n",
    "for i, (train, test) in enumerate(zip(train_accuracies, accuracies)):\n",
    "    axes[0, 0].annotate(f'{test:.3f}', (plot_depths[i], test), \n",
    "                       textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# 2. Overfitting Analysis (Accuracy Gap)\n",
    "accuracy_gaps = [train - test for train, test in zip(train_accuracies, accuracies)]\n",
    "bars = axes[0, 1].bar(plot_depths, accuracy_gaps, alpha=0.7, color='red')\n",
    "axes[0, 1].set_title('Overfitting Analysis (Train - Test Accuracy)', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('max_depth')\n",
    "axes[0, 1].set_ylabel('Accuracy Gap')\n",
    "axes[0, 1].set_xticks(plot_depths)\n",
    "axes[0, 1].set_xticklabels(plot_labels)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, gap in zip(bars, accuracy_gaps):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{gap:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Tree Complexity (Number of Nodes)\n",
    "bars = axes[1, 0].bar(plot_depths, tree_nodes, alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Tree Complexity (Number of Nodes)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('max_depth')\n",
    "axes[1, 0].set_ylabel('Number of Nodes')\n",
    "axes[1, 0].set_xticks(plot_depths)\n",
    "axes[1, 0].set_xticklabels(plot_labels)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, nodes in zip(bars, tree_nodes):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{nodes}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Combined Analysis\n",
    "ax2 = axes[1, 1].twinx()\n",
    "line1 = axes[1, 1].plot(plot_depths, accuracies, 'o-', color='blue', \n",
    "                       label='Test Accuracy', linewidth=3, markersize=8)\n",
    "line2 = ax2.plot(plot_depths, tree_nodes, 's-', color='orange', \n",
    "                label='Tree Nodes', linewidth=3, markersize=8)\n",
    "axes[1, 1].set_title('Test Accuracy vs Tree Complexity', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('max_depth')\n",
    "axes[1, 1].set_ylabel('Test Accuracy', color='blue')\n",
    "ax2.set_ylabel('Number of Nodes', color='orange')\n",
    "axes[1, 1].set_xticks(plot_depths)\n",
    "axes[1, 1].set_xticklabels(plot_labels)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "axes[1, 1].legend(lines, labels, loc='center right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/comprehensive_depth_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create individual accuracy plot for clarity\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(plot_depths, train_accuracies, 'o-', label='Training Accuracy', \n",
    "         linewidth=4, markersize=10, color='#2E86C1')\n",
    "plt.plot(plot_depths, accuracies, 's-', label='Test Accuracy', \n",
    "         linewidth=4, markersize=10, color='#E74C3C')\n",
    "\n",
    "plt.title('Decision Tree Accuracy vs. Max Depth (80/20 Split)', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('max_depth', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.xticks(ticks=plot_depths, labels=plot_labels, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylim(0.75, 1.02)\n",
    "\n",
    "# Add optimal point annotation\n",
    "optimal_test_acc = accuracies[optimal_idx]\n",
    "optimal_plot_depth = plot_depths[optimal_idx]\n",
    "plt.annotate(f'Optimal: {optimal_depth}\\nAccuracy: {optimal_test_acc:.3f}', \n",
    "             xy=(optimal_plot_depth, optimal_test_acc), \n",
    "             xytext=(optimal_plot_depth + 1, optimal_test_acc + 0.02),\n",
    "             arrowprops=dict(arrowstyle='->', color='black', lw=2),\n",
    "             fontsize=12, ha='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/accuracy_vs_depth_detailed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights on Depth vs. Accuracy\n",
    "\n",
    "**Comprehensive Analysis of Decision Tree Depth Impact:**\n",
    "\n",
    "1. **Underfitting (max_depth=2)**:\n",
    "   - Both training and test accuracies are relatively low\n",
    "   - The model is too simple to capture the underlying patterns in the data\n",
    "   - High bias, low variance scenario\n",
    "   - Tree has limited expressiveness to model complex relationships\n",
    "\n",
    "2. **Optimal Performance (max_depth=3-4)**:\n",
    "   - Test accuracy reaches its peak in this range\n",
    "   - Good balance between model complexity and generalization\n",
    "   - Minimal gap between training and test performance\n",
    "   - Sweet spot for bias-variance tradeoff\n",
    "   - Tree is complex enough to capture important patterns but not overly complex\n",
    "\n",
    "3. **Overfitting (max_depthâ‰¥5 and None)**:\n",
    "   - Training accuracy continues to increase, reaching 100% for unlimited depth\n",
    "   - Test accuracy plateaus or slightly decreases\n",
    "   - Growing gap between training and test performance indicates overfitting\n",
    "   - The model memorizes training data noise rather than learning generalizable patterns\n",
    "   - Increased tree complexity (more nodes) without performance benefit\n",
    "\n",
    "4. **Tree Complexity Analysis**:\n",
    "   - Number of nodes grows exponentially with increased depth\n",
    "   - More complex trees are harder to interpret and more prone to overfitting\n",
    "   - The optimal depth provides good performance with manageable complexity\n",
    "   - There's a clear trade-off between model interpretability and performance\n",
    "\n",
    "**Final Recommendation**: Based on this comprehensive analysis, **max_depth=3** provides the best balance between accuracy, generalization, and model interpretability for this heart disease dataset. This depth achieves near-optimal test accuracy while maintaining a reasonable tree size and avoiding overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}